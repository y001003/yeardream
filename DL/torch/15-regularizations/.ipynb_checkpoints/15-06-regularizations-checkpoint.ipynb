{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\n",
    "    '../data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "test = datasets.MNIST(\n",
    "    '../data', train=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784]) torch.Size([60000])\n",
      "input_size: 784, output_size: 10\n"
     ]
    }
   ],
   "source": [
    "x = train.data.float() / 255.\n",
    "y = train.targets\n",
    "\n",
    "x = x.view(x.size(0), -1)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "input_size = x.size(-1)\n",
    "output_size = int(max(y)) + 1\n",
    "\n",
    "print('input_size: %d, output_size: %d' % (input_size, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 48000 / Valid 12000 / Test 10000 samples.\n",
      "torch.Size([48000, 784]) torch.Size([48000])\n",
      "torch.Size([12000, 784]) torch.Size([12000])\n",
      "torch.Size([10000, 784]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# Train / Valid ratio\n",
    "ratios = [.8, .2]\n",
    "\n",
    "train_cnt = int(x.size(0) * ratios[0])\n",
    "valid_cnt = int(x.size(0) * ratios[1])\n",
    "test_cnt = len(test.data)\n",
    "cnts = [train_cnt, valid_cnt]\n",
    "\n",
    "print(\"Train %d / Valid %d / Test %d samples.\" % (train_cnt, valid_cnt, test_cnt))\n",
    "\n",
    "indices = torch.randperm(x.size(0))\n",
    "\n",
    "x = torch.index_select(x, dim=0, index=indices)\n",
    "y = torch.index_select(y, dim=0, index=indices)\n",
    "\n",
    "x = list(x.split(cnts, dim=0))\n",
    "y = list(y.split(cnts, dim=0))\n",
    "\n",
    "x += [(test.data.float() / 255.).view(test_cnt, -1)]\n",
    "y += [test.targets]\n",
    "\n",
    "for x_i, y_i in zip(x, y):\n",
    "    print(x_i.size(), y_i.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Regularized Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 output_size,\n",
    "                 use_batch_norm=True,\n",
    "                 dropout_p=.4):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        def get_regularizer(use_batch_norm, size):\n",
    "            return nn.BatchNorm1d(size) if use_batch_norm else nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_size, output_size),\n",
    "            nn.LeakyReLU(),\n",
    "            get_regularizer(use_batch_norm, output_size),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, input_size)\n",
    "        y = self.block(x)\n",
    "        # |y| = (batch_size, output_size)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 output_size,\n",
    "                 use_batch_norm=True,\n",
    "                 dropout_p=.4):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            Block(input_size, 500, use_batch_norm, dropout_p),\n",
    "            Block(500, 400, use_batch_norm, dropout_p),\n",
    "            Block(400, 300, use_batch_norm, dropout_p),\n",
    "            Block(300, 200, use_batch_norm, dropout_p),\n",
    "            Block(200, 100, use_batch_norm, dropout_p),\n",
    "            nn.Linear(100, output_size),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, input_size)        \n",
    "        y = self.layers(x)\n",
    "        # |y| = (batch_size, output_size)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (layers): Sequential(\n",
       "    (0): Block(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=500, out_features=400, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=400, out_features=300, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=200, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (6): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(input_size,\n",
    "                output_size,\n",
    "                use_batch_norm=True)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move to GPU if it is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "x = [x_i.to(device) for x_i in x]\n",
    "y = [y_i.to(device) for y_i in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 256\n",
    "print_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "lowest_loss = np.inf\n",
    "best_model = None\n",
    "\n",
    "early_stop = 50\n",
    "lowest_epoch = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history, valid_history = [], []\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    indices = torch.randperm(x[0].size(0)).to(device)\n",
    "    x_ = torch.index_select(x[0], dim=0, index=indices)\n",
    "    y_ = torch.index_select(y[0], dim=0, index=indices)\n",
    "    \n",
    "    x_ = x_.split(batch_size, dim=0)\n",
    "    y_ = y_.split(batch_size, dim=0)\n",
    "    \n",
    "    train_loss, valid_loss = 0, 0\n",
    "    y_hat = []\n",
    "    \n",
    "    for x_i, y_i in zip(x_, y_):\n",
    "        y_hat_i = model(x_i)\n",
    "        loss = crit(y_hat_i, y_i.squeeze())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()        \n",
    "        train_loss += float(loss) # This is very important to prevent memory leak.\n",
    "\n",
    "    train_loss = train_loss / len(x_)\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_ = x[1].split(batch_size, dim=0)\n",
    "        y_ = y[1].split(batch_size, dim=0)\n",
    "        \n",
    "        valid_loss = 0\n",
    "        \n",
    "        for x_i, y_i in zip(x_, y_):\n",
    "            y_hat_i = model(x_i)\n",
    "            loss = crit(y_hat_i, y_i.squeeze())\n",
    "            \n",
    "            valid_loss += float(loss)\n",
    "            \n",
    "            y_hat += [y_hat_i]\n",
    "            \n",
    "    valid_loss = valid_loss / len(x_)\n",
    "    \n",
    "    train_history += [train_loss]\n",
    "    valid_history += [valid_loss]\n",
    "        \n",
    "    if (i + 1) % print_interval == 0:\n",
    "        print('Epoch %d: train loss=%.4e  valid_loss=%.4e  lowest_loss=%.4e' % (\n",
    "            i + 1,\n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            lowest_loss,\n",
    "        ))\n",
    "        \n",
    "    if valid_loss <= lowest_loss:\n",
    "        lowest_loss = valid_loss\n",
    "        lowest_epoch = i\n",
    "        \n",
    "        best_model = deepcopy(model.state_dict())\n",
    "    else:\n",
    "        if early_stop > 0 and lowest_epoch + early_stop < i + 1:\n",
    "            print(\"There is no improvement during last %d epochs.\" % early_stop)\n",
    "            break\n",
    "\n",
    "print(\"The best validation loss from epoch %d: %.4e\" % (lowest_epoch + 1, lowest_loss))\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_from = 0\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.grid(True)\n",
    "plt.title(\"Train / Valid Loss History\")\n",
    "plt.plot(\n",
    "    range(plot_from, len(train_history)), train_history[plot_from:],\n",
    "    range(plot_from, len(valid_history)), valid_history[plot_from:],\n",
    ")\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "y_hat = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_ = x[-1].split(batch_size, dim=0)\n",
    "    y_ = y[-1].split(batch_size, dim=0)\n",
    "\n",
    "    for x_i, y_i in zip(x_, y_):\n",
    "        y_hat_i = model(x_i)\n",
    "        loss = crit(y_hat_i, y_i.squeeze())\n",
    "\n",
    "        test_loss += loss # Gradient is already detached.\n",
    "\n",
    "        y_hat += [y_hat_i]\n",
    "\n",
    "test_loss = test_loss / len(x_)\n",
    "y_hat = torch.cat(y_hat, dim=0)\n",
    "\n",
    "print(\"Test loss: %.4e\" % test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_cnt = (y[-1].squeeze() == torch.argmax(y_hat, dim=-1)).sum()\n",
    "total_cnt = float(y[-1].size(0))\n",
    "\n",
    "print('Accuracy: %.4f' % (correct_cnt / total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y[-1], torch.argmax(y_hat, dim=-1)),\n",
    "             index=['true_%d' % i for i in range(10)],\n",
    "             columns=['pred_%d' % i for i in range(10)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
