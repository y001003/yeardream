{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5446ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import scipy as sp\n",
    "import PIL\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras import models, layers, Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, ZeroPadding2D\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import EfficientNetB4, EfficientNetB6, ResNet50V2\n",
    "#from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ed8bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size: 한번에 forward & Backword 하는 샘플의 수\n",
    "batch_size = 32\n",
    "\n",
    "# Training 수\n",
    "epochs = 50\n",
    "\n",
    "# Weight 조절 parameter\n",
    "LearningRate = 1e-3 # 0.001\n",
    "Decay = 1e-6\n",
    "\n",
    "img_width = 224\n",
    "img_height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1681456",
   "metadata": {},
   "source": [
    "## 디렉토리 경로 설정 필요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7651c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디렉토리 경로 설정 필요\n",
    "# CurrentDirectory = \"C:/Users/sosal/.jupyter/Lectures/CNN/\"\n",
    "CurrentDirectory = \"./\"\n",
    "\n",
    "train_directory = CurrentDirectory + 'TRAIN/'\n",
    "test_directory  = CurrentDirectory + 'TEST/'\n",
    "model_directory = CurrentDirectory + 'MODEL/'\n",
    "tensorboard_directory = CurrentDirectory + 'Tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9e112a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VGG_16의 구현 2016?\n",
    "# def VGG_16():\n",
    "#     model = Sequential()\n",
    "#     # convolution / pooling의 반복\n",
    "#     model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "#     model.add(ZeroPadding2D((1,1)))\n",
    "#     model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#     #top layer of the VGG net\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e66e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vggModel = VGG_16()\n",
    "# vggModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16251997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 Return\n",
    "VGGModel = tf.keras.applications.VGG16(include_top=False,\n",
    "    weights='imagenet', input_tensor=None, input_shape=(img_width,img_height,3), pooling=None)\n",
    "# 마지막 prediction layer를 위한 작업\n",
    "\n",
    "x = GlobalAveragePooling2D()(VGGModel.output)\n",
    "# predictions = Dense(2, activation='softmax')(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Input ~ Output 연결해주기\n",
    "DeepLearning = Model(inputs=VGGModel.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "DeepLearning.compile(optimizer=\n",
    "         SGD(lr=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['acc']\n",
    ") # 나이를, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62666b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 14,715,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DeepLearning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abe59194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online-augmentation 적용 Generator\n",
    "# 1. 이미지를 전부다 불러서 램 (메모리)에 올릴 수 없기 때문\n",
    "# 2. 이미지는 Augmentation을 해주는게 좋아서\n",
    "\n",
    "DATAGEN_TRAIN = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\",\n",
    "    validation_split=0.10) # Train / Validation\n",
    "\n",
    "# Online-augmentation 비적용 Generator (Test용)\n",
    "DATAGEN_TEST = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b34dae29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 719 images belonging to 3 classes.\n",
      "Found 79 images belonging to 3 classes.\n",
      "Found 106 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generator의 instance 생성 (Train)\n",
    "TRAIN_GENERATOR = DATAGEN_TRAIN.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode= \"categorical\",\n",
    "    subset = \"training\")\n",
    "\n",
    "VALID_GENERATOR = DATAGEN_TRAIN.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset = \"validation\")\n",
    "\n",
    "# Generator의 instance 생성 (Test)\n",
    "TEST_GENERATOR = DATAGEN_TEST.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "632246af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c apple tensorflow-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb880a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-macos in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (2.9.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (2.9.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (1.6.3)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (21.3)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (63.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (14.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (1.15.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (3.19.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (1.12)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (3.6.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (1.14.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (4.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (1.22.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-macos) (1.45.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow-macos) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (2.9.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (2.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (0.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (3.3.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from packaging->tensorflow-macos) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos) (0.2.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-macos) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-macos) (4.11.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-macos) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-macos) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow-macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50891b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-metal in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (0.5.0)\r\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-metal) (1.15.0)\r\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages (from tensorflow-metal) (0.37.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "286cd734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15ce47f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "                         /Users/krc/miniforge3/envs/newwindow\r\n",
      "base                     /opt/homebrew/Caskroom/miniforge/base\r\n",
      "fastcampus               /opt/homebrew/Caskroom/miniforge/base/envs/fastcampus\r\n",
      "pycaret                  /opt/homebrew/Caskroom/miniforge/base/envs/pycaret\r\n",
      "pycaret2                 /opt/homebrew/Caskroom/miniforge/base/envs/pycaret2\r\n",
      "pycaret3                 /opt/homebrew/Caskroom/miniforge/base/envs/pycaret3\r\n",
      "tensorflow            *  /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a09cf2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call-back 함수\n",
    "\n",
    "# CheckPoint: Epoch 마다 validation 성능을 검증하여, best performance 일 경우 저장\n",
    "CP = ModelCheckpoint(filepath=model_directory+'VGG19-{epoch:03d}-{val_loss:.4f}-{val_acc:.4f}.hdf5',\n",
    "            monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# 학습과정 진행사항 확인\n",
    "TB = TensorBoard(log_dir=tensorboard_directory, write_graph=True, write_images=True)\n",
    "\n",
    "# Learning Rate 줄여나가기\n",
    "LR = ReduceLROnPlateau(monitor='val_loss',factor=0.8,patience=3, verbose=1, min_lr=1e-8)\n",
    "\n",
    "CALLBACK = [CP, TB, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7cf30e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fb/fgwpc_kd3dxdcfsnm_9w3wv40000gn/T/ipykernel_35601/1291605744.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  DeepLearning.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6367 - acc: 0.6667 \n",
      "Epoch 1: val_acc did not improve from 0.66667\n",
      "23/23 [==============================] - 267s 12s/step - loss: 0.6367 - acc: 0.6667 - val_loss: 0.6367 - val_acc: 0.6667 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6367 - acc: 0.6667 \n",
      "Epoch 2: val_acc did not improve from 0.66667\n",
      "23/23 [==============================] - 273s 12s/step - loss: 0.6367 - acc: 0.6667 - val_loss: 0.6368 - val_acc: 0.6667 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6367 - acc: 0.6667 \n",
      "Epoch 3: val_acc did not improve from 0.66667\n",
      "23/23 [==============================] - 274s 12s/step - loss: 0.6367 - acc: 0.6667 - val_loss: 0.6367 - val_acc: 0.6667 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6366 - acc: 0.6667 \n",
      "Epoch 4: val_acc did not improve from 0.66667\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "23/23 [==============================] - 268s 12s/step - loss: 0.6366 - acc: 0.6667 - val_loss: 0.6367 - val_acc: 0.6667 - lr: 0.0010\n",
      "Epoch 5/15\n",
      " 3/23 [==>...........................] - ETA: 3:53 - loss: 0.6367 - acc: 0.6667"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m########## Training Start\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mDeepLearning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTRAIN_GENERATOR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 데이터가 너무 클 경우 1-epoch을 못하는 경우\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCALLBACK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALID_GENERATOR\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py:2209\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2199\u001b[0m \n\u001b[1;32m   2200\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;124;03m  this endpoint.\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2204\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2208\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m-> 2209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefun\u001b[39m(func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2765\u001b[0m           input_signature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2766\u001b[0m           autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2767\u001b[0m           experimental_autograph_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2768\u001b[0m           reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2769\u001b[0m   \u001b[38;5;124;03m\"\"\"Compiles a Python function into a callable TensorFlow graph.\u001b[39;00m\n\u001b[1;32m   2770\u001b[0m \n\u001b[1;32m   2771\u001b[0m \u001b[38;5;124;03m  `defun` (short for \"define function\") compiles a Python function\u001b[39;00m\n\u001b[1;32m   2772\u001b[0m \u001b[38;5;124;03m  composed of TensorFlow operations into a callable that executes a `tf.Graph`\u001b[39;00m\n\u001b[1;32m   2773\u001b[0m \u001b[38;5;124;03m  containing those operations. The callable produced by `defun` contains only\u001b[39;00m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;124;03m  the subgraph of TensorFlow operations that were executed when the Python\u001b[39;00m\n\u001b[1;32m   2775\u001b[0m \u001b[38;5;124;03m  function was called with a particular input signature, defined as a list\u001b[39;00m\n\u001b[1;32m   2776\u001b[0m \u001b[38;5;124;03m  of the shapes and dtypes of the Python function's Tensor-valued arguments and\u001b[39;00m\n\u001b[1;32m   2777\u001b[0m \u001b[38;5;124;03m  the values of its non-Tensor Python objects.\u001b[39;00m\n\u001b[1;32m   2778\u001b[0m \n\u001b[1;32m   2779\u001b[0m \u001b[38;5;124;03m  When eager execution is enabled, the ability to create graphs from Python\u001b[39;00m\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;124;03m  functions makes it possible to incrementally trade off debuggability and\u001b[39;00m\n\u001b[1;32m   2781\u001b[0m \u001b[38;5;124;03m  interactivity for performance.  Functions compiled with `defun` cannot be\u001b[39;00m\n\u001b[1;32m   2782\u001b[0m \u001b[38;5;124;03m  inspected with `pdb`; however, executing a graph\u001b[39;00m\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;124;03m  generated by `defun` sometimes takes less time and memory than eagerly\u001b[39;00m\n\u001b[1;32m   2784\u001b[0m \u001b[38;5;124;03m  executing the corresponding Python function, since specifying computations as\u001b[39;00m\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;124;03m  graphs allows for optimizations like automatic buffer reuse and\u001b[39;00m\n\u001b[1;32m   2786\u001b[0m \u001b[38;5;124;03m  parallelization among ops. Note that executing a `defun`-compiled function\u001b[39;00m\n\u001b[1;32m   2787\u001b[0m \u001b[38;5;124;03m  incurs a small constant overhead, so eagerly executing sufficiently small\u001b[39;00m\n\u001b[1;32m   2788\u001b[0m \u001b[38;5;124;03m  Python functions might take less time than executing their corresponding\u001b[39;00m\n\u001b[1;32m   2789\u001b[0m \u001b[38;5;124;03m  `defun`-generated graphs.\u001b[39;00m\n\u001b[1;32m   2790\u001b[0m \n\u001b[1;32m   2791\u001b[0m \u001b[38;5;124;03m  For a Python function to be compatible with `defun`, all of its arguments must\u001b[39;00m\n\u001b[1;32m   2792\u001b[0m \u001b[38;5;124;03m  be hashable Python objects or lists thereof. The function itself may not\u001b[39;00m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;124;03m  modify the list/map structure of its arguments. Additionally, it must return\u001b[39;00m\n\u001b[1;32m   2794\u001b[0m \u001b[38;5;124;03m  zero or more `tf.Tensor` objects. If the Python function returns\u001b[39;00m\n\u001b[1;32m   2795\u001b[0m \u001b[38;5;124;03m  a `tf.Variable`, its compiled version will return the value of that variable\u001b[39;00m\n\u001b[1;32m   2796\u001b[0m \u001b[38;5;124;03m  as a `tf.Tensor`.\u001b[39;00m\n\u001b[1;32m   2797\u001b[0m \n\u001b[1;32m   2798\u001b[0m \u001b[38;5;124;03m  Executing a graph generated by `defun` respects device annotations (i.e.,\u001b[39;00m\n\u001b[1;32m   2799\u001b[0m \u001b[38;5;124;03m  all `with tf.device` directives present in a Python function will also be\u001b[39;00m\n\u001b[1;32m   2800\u001b[0m \u001b[38;5;124;03m  present in its corresponding graph), but it is not yet possible to execute the\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;124;03m  generated graphs across multiple machines.\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \n\u001b[1;32m   2803\u001b[0m \u001b[38;5;124;03m  _Example Usage_\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m \n\u001b[1;32m   2805\u001b[0m \u001b[38;5;124;03m  ```python\u001b[39;00m\n\u001b[1;32m   2806\u001b[0m \u001b[38;5;124;03m  import tensorflow as tf\u001b[39;00m\n\u001b[1;32m   2807\u001b[0m \n\u001b[1;32m   2808\u001b[0m \u001b[38;5;124;03m  tf.compat.v1.enable_eager_execution()\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \n\u001b[1;32m   2810\u001b[0m \u001b[38;5;124;03m  # A simple example.\u001b[39;00m\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;124;03m  def f(x, y):\u001b[39;00m\n\u001b[1;32m   2812\u001b[0m \u001b[38;5;124;03m    return tf.reduce_mean(tf.multiply(x ** 2, 3) + y)\u001b[39;00m\n\u001b[1;32m   2813\u001b[0m \n\u001b[1;32m   2814\u001b[0m \u001b[38;5;124;03m  g = tf.contrib.eager.defun(f)\u001b[39;00m\n\u001b[1;32m   2815\u001b[0m \n\u001b[1;32m   2816\u001b[0m \u001b[38;5;124;03m  x = tf.constant([[2.0, 3.0]])\u001b[39;00m\n\u001b[1;32m   2817\u001b[0m \u001b[38;5;124;03m  y = tf.constant([[3.0, -2.0]])\u001b[39;00m\n\u001b[1;32m   2818\u001b[0m \n\u001b[1;32m   2819\u001b[0m \u001b[38;5;124;03m  # `f` and `g` will return the same value, but `g` will be executed as a\u001b[39;00m\n\u001b[1;32m   2820\u001b[0m \u001b[38;5;124;03m  # TensorFlow graph.\u001b[39;00m\n\u001b[1;32m   2821\u001b[0m \u001b[38;5;124;03m  assert f(x, y).numpy() == g(x, y).numpy()\u001b[39;00m\n\u001b[1;32m   2822\u001b[0m \n\u001b[1;32m   2823\u001b[0m \u001b[38;5;124;03m  # `defun` is capable of compiling Python functions that close over Python\u001b[39;00m\n\u001b[1;32m   2824\u001b[0m \u001b[38;5;124;03m  # objects, including Tensors and Variables.\u001b[39;00m\n\u001b[1;32m   2825\u001b[0m \u001b[38;5;124;03m  @tf.contrib.eager.defun\u001b[39;00m\n\u001b[1;32m   2826\u001b[0m \u001b[38;5;124;03m  def h():\u001b[39;00m\n\u001b[1;32m   2827\u001b[0m \u001b[38;5;124;03m    return f(x, y)\u001b[39;00m\n\u001b[1;32m   2828\u001b[0m \n\u001b[1;32m   2829\u001b[0m \u001b[38;5;124;03m  assert (h().numpy() == f(x, y).numpy()).all()\u001b[39;00m\n\u001b[1;32m   2830\u001b[0m \n\u001b[1;32m   2831\u001b[0m \u001b[38;5;124;03m  # `defun` automatically lifts variables out of the graphs it creates,\u001b[39;00m\n\u001b[1;32m   2832\u001b[0m \u001b[38;5;124;03m  # allowing you to compile the `call` methods of `tf.keras.layers.Layer` and\u001b[39;00m\n\u001b[1;32m   2833\u001b[0m \u001b[38;5;124;03m  # `tf.keras.Model` objects.\u001b[39;00m\n\u001b[1;32m   2834\u001b[0m \u001b[38;5;124;03m  class MyModel(tf.keras.Model):\u001b[39;00m\n\u001b[1;32m   2835\u001b[0m \n\u001b[1;32m   2836\u001b[0m \u001b[38;5;124;03m    def __init__(self, keep_probability=0.2):\u001b[39;00m\n\u001b[1;32m   2837\u001b[0m \u001b[38;5;124;03m      super(MyModel, self).__init__()\u001b[39;00m\n\u001b[1;32m   2838\u001b[0m \u001b[38;5;124;03m      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\u001b[39;00m\n\u001b[1;32m   2839\u001b[0m \u001b[38;5;124;03m      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\u001b[39;00m\n\u001b[1;32m   2840\u001b[0m \u001b[38;5;124;03m      self.keep_probability = keep_probability\u001b[39;00m\n\u001b[1;32m   2841\u001b[0m \n\u001b[1;32m   2842\u001b[0m \u001b[38;5;124;03m    @tf.contrib.eager.defun\u001b[39;00m\n\u001b[1;32m   2843\u001b[0m \u001b[38;5;124;03m    def call(self, inputs, training=True):\u001b[39;00m\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;124;03m      x = self.dense2(self.dense1(inputs))\u001b[39;00m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;124;03m      if training:\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;124;03m        return tf.nn.dropout(x, self.keep_probability)\u001b[39;00m\n\u001b[1;32m   2847\u001b[0m \u001b[38;5;124;03m      else:\u001b[39;00m\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;124;03m        return x\u001b[39;00m\n\u001b[1;32m   2849\u001b[0m \n\u001b[1;32m   2850\u001b[0m \u001b[38;5;124;03m  model = MyModel()\u001b[39;00m\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;124;03m  model(x, training=True)  # executes a graph, with dropout\u001b[39;00m\n\u001b[1;32m   2852\u001b[0m \u001b[38;5;124;03m  model(x, training=False) # executes a graph, without dropout\u001b[39;00m\n\u001b[1;32m   2853\u001b[0m \n\u001b[1;32m   2854\u001b[0m \u001b[38;5;124;03m  # `defun`-compiled functions are differentiable.\u001b[39;00m\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;124;03m  optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\u001b[39;00m\n\u001b[1;32m   2856\u001b[0m \u001b[38;5;124;03m  with tf.GradientTape() as tape:\u001b[39;00m\n\u001b[1;32m   2857\u001b[0m \u001b[38;5;124;03m    outputs = model(x)\u001b[39;00m\n\u001b[1;32m   2858\u001b[0m \u001b[38;5;124;03m  gradient = tape.gradient(outputs, model.trainable_variables)\u001b[39;00m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;124;03m  optimizer.apply_gradients((grad, var) for grad, var in zip(gradient,\u001b[39;00m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;124;03m                            model.trainable_variables))\u001b[39;00m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;124;03m  ```\u001b[39;00m\n\u001b[1;32m   2862\u001b[0m \n\u001b[1;32m   2863\u001b[0m \u001b[38;5;124;03m  When using `defun`, there are subtleties regarding inputs, Python control\u001b[39;00m\n\u001b[1;32m   2864\u001b[0m \u001b[38;5;124;03m  flow, and variable creation that one should be aware of. For concreteness, let\u001b[39;00m\n\u001b[1;32m   2865\u001b[0m \u001b[38;5;124;03m  `f` be a Python function that returns zero or more `tf.Tensor` objects and\u001b[39;00m\n\u001b[1;32m   2866\u001b[0m \u001b[38;5;124;03m  let `F = defun(f)`. `F` builds a graph for each unique input signature it\u001b[39;00m\n\u001b[1;32m   2867\u001b[0m \u001b[38;5;124;03m  sees, Python control flow is baked into graphs, and operations related to\u001b[39;00m\n\u001b[1;32m   2868\u001b[0m \u001b[38;5;124;03m  variable initialization are automatically lifted out of the graphs that `F`\u001b[39;00m\n\u001b[1;32m   2869\u001b[0m \u001b[38;5;124;03m  generates and placed in the eager context if executing eagerly or into an\u001b[39;00m\n\u001b[1;32m   2870\u001b[0m \u001b[38;5;124;03m  outer graph otherwise.\u001b[39;00m\n\u001b[1;32m   2871\u001b[0m \n\u001b[1;32m   2872\u001b[0m \u001b[38;5;124;03m  _Input Signatures_\u001b[39;00m\n\u001b[1;32m   2873\u001b[0m \n\u001b[1;32m   2874\u001b[0m \u001b[38;5;124;03m  By default, `F = tf.contrib.eager.defun(f)` instantiates a separate graph\u001b[39;00m\n\u001b[1;32m   2875\u001b[0m \u001b[38;5;124;03m  for every unique sequence of the shapes and dtypes of Tensor arguments and\u001b[39;00m\n\u001b[1;32m   2876\u001b[0m \u001b[38;5;124;03m  the values of Python objects it is invoked with. For example, calling\u001b[39;00m\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;124;03m  `F(tf.random.uniform([2])` will execute a different graph than\u001b[39;00m\n\u001b[1;32m   2878\u001b[0m \u001b[38;5;124;03m  `F(tf.random.uniform([3])` because the two inputs have different shapes.\u001b[39;00m\n\u001b[1;32m   2879\u001b[0m \u001b[38;5;124;03m  The first time that `F(*args, **kwargs)` is called with a particular sequence\u001b[39;00m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;124;03m  of Tensor shapes and dtypes and Python values, it constructs a graph by\u001b[39;00m\n\u001b[1;32m   2881\u001b[0m \u001b[38;5;124;03m  tracing the execution of `f(*args, **kwargs)`; this graph is bound to an\u001b[39;00m\n\u001b[1;32m   2882\u001b[0m \u001b[38;5;124;03m  input signature inferred from `(*args, **kwargs)` and cached for future reuse.\u001b[39;00m\n\u001b[1;32m   2883\u001b[0m \n\u001b[1;32m   2884\u001b[0m \u001b[38;5;124;03m  NumPy arrays passed as inputs to `F` are converted to `tf.Tensor` objects\u001b[39;00m\n\u001b[1;32m   2885\u001b[0m \u001b[38;5;124;03m  before being passed to `f`, and are treated as Tensors for caching. This\u001b[39;00m\n\u001b[1;32m   2886\u001b[0m \u001b[38;5;124;03m  allows a function to be called multiple times with NumPy arrays having\u001b[39;00m\n\u001b[1;32m   2887\u001b[0m \u001b[38;5;124;03m  different values but the same shape and dtype without re-tracing each time.\u001b[39;00m\n\u001b[1;32m   2888\u001b[0m \n\u001b[1;32m   2889\u001b[0m \u001b[38;5;124;03m  `tf.contrib.eager.defun` caches graphs for your convenience, letting you\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;124;03m  define TensorFlow functions without explicitly specifying their signatures.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \u001b[38;5;124;03m  However, this policy is conservative and potentially expensive; for example,\u001b[39;00m\n\u001b[1;32m   2892\u001b[0m \u001b[38;5;124;03m  when different invocations of your function have differently-shaped Tensor\u001b[39;00m\n\u001b[1;32m   2893\u001b[0m \u001b[38;5;124;03m  inputs, this policy might generate more graph functions than necessary. To\u001b[39;00m\n\u001b[1;32m   2894\u001b[0m \u001b[38;5;124;03m  eliminate such costs, `tf.contrib.eager.defun` allows you to supply an\u001b[39;00m\n\u001b[1;32m   2895\u001b[0m \u001b[38;5;124;03m  optional `input_signature` argument specifying the shapes and dtypes of the\u001b[39;00m\n\u001b[1;32m   2896\u001b[0m \u001b[38;5;124;03m  inputs. In particular, the shapes may be partially unspecified, with `None`s\u001b[39;00m\n\u001b[1;32m   2897\u001b[0m \u001b[38;5;124;03m  in the unknown dimensions.  When an input signature is provided,\u001b[39;00m\n\u001b[1;32m   2898\u001b[0m \u001b[38;5;124;03m  `tf.contrib.eager.defun` will only instantiate a single graph for the\u001b[39;00m\n\u001b[1;32m   2899\u001b[0m \u001b[38;5;124;03m  decorated Python function. The following is an example:\u001b[39;00m\n\u001b[1;32m   2900\u001b[0m \n\u001b[1;32m   2901\u001b[0m \u001b[38;5;124;03m  ```python\u001b[39;00m\n\u001b[1;32m   2902\u001b[0m \u001b[38;5;124;03m  import tensorflow as tf\u001b[39;00m\n\u001b[1;32m   2903\u001b[0m \n\u001b[1;32m   2904\u001b[0m \u001b[38;5;124;03m  # The first `TensorSpec` below describes the shape and dtype of `words`,\u001b[39;00m\n\u001b[1;32m   2905\u001b[0m \u001b[38;5;124;03m  # and the second describes the shape and dtype of `another_tensor`. Note that\u001b[39;00m\n\u001b[1;32m   2906\u001b[0m \u001b[38;5;124;03m  # the last dimension of the `words` `TensorSpec` is left unspecified.\u001b[39;00m\n\u001b[1;32m   2907\u001b[0m \u001b[38;5;124;03m  @tf.contrib.eager.defun(input_signature=[\u001b[39;00m\n\u001b[1;32m   2908\u001b[0m \u001b[38;5;124;03m    tf.contrib.eager.TensorSpec(shape=[50, 300, None], dtype=tf.float32),\u001b[39;00m\n\u001b[1;32m   2909\u001b[0m \u001b[38;5;124;03m    tf.contrib.eager.TensorSpec(shape=[300, 100], dtype=tf.float32)\u001b[39;00m\n\u001b[1;32m   2910\u001b[0m \u001b[38;5;124;03m  ])\u001b[39;00m\n\u001b[1;32m   2911\u001b[0m \u001b[38;5;124;03m  def my_sequence_model(words, another_tensor):\u001b[39;00m\n\u001b[1;32m   2912\u001b[0m \u001b[38;5;124;03m    ...\u001b[39;00m\n\u001b[1;32m   2913\u001b[0m \n\u001b[1;32m   2914\u001b[0m \u001b[38;5;124;03m  # Note how the third dimension of the first input can vary freely.\u001b[39;00m\n\u001b[1;32m   2915\u001b[0m \u001b[38;5;124;03m  words = tf.random.uniform(([50, 300, 10])\u001b[39;00m\n\u001b[1;32m   2916\u001b[0m \u001b[38;5;124;03m  second_input = tf.random.uniform([300, 100])\u001b[39;00m\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;124;03m  my_sequence_model(words, second_input)\u001b[39;00m\n\u001b[1;32m   2918\u001b[0m \n\u001b[1;32m   2919\u001b[0m \u001b[38;5;124;03m  words = tf.random.uniform(([50, 300, 20])\u001b[39;00m\n\u001b[1;32m   2920\u001b[0m \u001b[38;5;124;03m  my_sequence_model(words, second_input)\u001b[39;00m\n\u001b[1;32m   2921\u001b[0m \n\u001b[1;32m   2922\u001b[0m \u001b[38;5;124;03m  # Passing an input with an incompatible shape will raise an error.\u001b[39;00m\n\u001b[1;32m   2923\u001b[0m \u001b[38;5;124;03m  words = tf.random.uniform(([50, 100, 20])\u001b[39;00m\n\u001b[1;32m   2924\u001b[0m \u001b[38;5;124;03m  my_sequence_model(words, second_input)  # <---- This will raise an error.\u001b[39;00m\n\u001b[1;32m   2925\u001b[0m \n\u001b[1;32m   2926\u001b[0m \u001b[38;5;124;03m  ```\u001b[39;00m\n\u001b[1;32m   2927\u001b[0m \n\u001b[1;32m   2928\u001b[0m \u001b[38;5;124;03m  Python functions that are compiled with an `input_signature` must only accept\u001b[39;00m\n\u001b[1;32m   2929\u001b[0m \u001b[38;5;124;03m  Tensors as arguments and must not take unnamed keyword arguments (**kwargs).\u001b[39;00m\n\u001b[1;32m   2930\u001b[0m \n\u001b[1;32m   2931\u001b[0m \u001b[38;5;124;03m  _Tracing_\u001b[39;00m\n\u001b[1;32m   2932\u001b[0m \n\u001b[1;32m   2933\u001b[0m \u001b[38;5;124;03m  Be aware that because `F` only logs TensorFlow operations, all the other\u001b[39;00m\n\u001b[1;32m   2934\u001b[0m \u001b[38;5;124;03m  Python code that `f` executes will only shape the _construction_ of the graphs\u001b[39;00m\n\u001b[1;32m   2935\u001b[0m \u001b[38;5;124;03m  that `F` executes: the Python code won't be executed when the graphs\u001b[39;00m\n\u001b[1;32m   2936\u001b[0m \u001b[38;5;124;03m  themselves are executed, though it will be executed every time the Python\u001b[39;00m\n\u001b[1;32m   2937\u001b[0m \u001b[38;5;124;03m  function is traced (and a given Python function might be traced multiple\u001b[39;00m\n\u001b[1;32m   2938\u001b[0m \u001b[38;5;124;03m  times, once for each input signature it is invoked with). For example, whereas\u001b[39;00m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;124;03m  the Python function\u001b[39;00m\n\u001b[1;32m   2940\u001b[0m \n\u001b[1;32m   2941\u001b[0m \u001b[38;5;124;03m  ```python\u001b[39;00m\n\u001b[1;32m   2942\u001b[0m \u001b[38;5;124;03m  import tensorflow as tf\u001b[39;00m\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;124;03m  import numpy as np\u001b[39;00m\n\u001b[1;32m   2944\u001b[0m \n\u001b[1;32m   2945\u001b[0m \u001b[38;5;124;03m  tf.compat.v1.enable_eager_execution()\u001b[39;00m\n\u001b[1;32m   2946\u001b[0m \n\u001b[1;32m   2947\u001b[0m \u001b[38;5;124;03m  def add_noise():\u001b[39;00m\n\u001b[1;32m   2948\u001b[0m \u001b[38;5;124;03m    return tf.eye(5) + np.random.randn(5, 5)\u001b[39;00m\n\u001b[1;32m   2949\u001b[0m \u001b[38;5;124;03m  ```\u001b[39;00m\n\u001b[1;32m   2950\u001b[0m \n\u001b[1;32m   2951\u001b[0m \u001b[38;5;124;03m  will return a different output everytime it is invoked, the compiled function\u001b[39;00m\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;124;03m  `compiled = tf.contrib.eager.defun(add_noise)` will return the same value\u001b[39;00m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;124;03m  every time it is called, since a particular random offset generated by NumPy\u001b[39;00m\n\u001b[1;32m   2954\u001b[0m \u001b[38;5;124;03m  will be inserted into the graph as a TensorFlow constant. The solution is to\u001b[39;00m\n\u001b[1;32m   2955\u001b[0m \u001b[38;5;124;03m  replace the call to `np.random.randn` with `tf.random.normal((5, 5))`.\u001b[39;00m\n\u001b[0;32m-> 2956\u001b[0m \n\u001b[1;32m   2957\u001b[0m \u001b[38;5;124;03m  _Python Side-Effects_\u001b[39;00m\n\u001b[1;32m   2958\u001b[0m \n\u001b[1;32m   2959\u001b[0m \u001b[38;5;124;03m  A corollary of the previous discussion on tracing is the following: If a\u001b[39;00m\n\u001b[1;32m   2960\u001b[0m \u001b[38;5;124;03m  Python function `f` has Python side-effects, then executing `f` multiple times\u001b[39;00m\n\u001b[1;32m   2961\u001b[0m \u001b[38;5;124;03m  will not necessarily be semantically equivalent to executing `F =\u001b[39;00m\n\u001b[1;32m   2962\u001b[0m \u001b[38;5;124;03m  tf.contrib.eager.defun(f)` multiple times; this difference is due to the fact\u001b[39;00m\n\u001b[1;32m   2963\u001b[0m \u001b[38;5;124;03m  that `defun` only captures the subgraph of TensorFlow operations that is\u001b[39;00m\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;124;03m  constructed when `f` is called in a graph-building context.\u001b[39;00m\n\u001b[1;32m   2965\u001b[0m \n\u001b[1;32m   2966\u001b[0m \u001b[38;5;124;03m  _Python Control Flow_\u001b[39;00m\n\u001b[1;32m   2967\u001b[0m \n\u001b[1;32m   2968\u001b[0m \u001b[38;5;124;03m  The structure of many machine learning computations depend upon whether one is\u001b[39;00m\n\u001b[1;32m   2969\u001b[0m \u001b[38;5;124;03m  training or validating, and it is common to nest specialized logic under `if\u001b[39;00m\n\u001b[1;32m   2970\u001b[0m \u001b[38;5;124;03m  training:` blocks. By mapping each input signature to a unique graph, `defun`\u001b[39;00m\n\u001b[1;32m   2971\u001b[0m \u001b[38;5;124;03m  lets users transparently compile such code, as the following code snippet\u001b[39;00m\n\u001b[1;32m   2972\u001b[0m \u001b[38;5;124;03m  demonstrates:\u001b[39;00m\n\u001b[1;32m   2973\u001b[0m \n\u001b[1;32m   2974\u001b[0m \u001b[38;5;124;03m  ```python\u001b[39;00m\n\u001b[1;32m   2975\u001b[0m \u001b[38;5;124;03m  import tensorflow as tf\u001b[39;00m\n\u001b[1;32m   2976\u001b[0m \n\u001b[1;32m   2977\u001b[0m \u001b[38;5;124;03m  tf.compat.v1.enable_eager_execution()\u001b[39;00m\n\u001b[1;32m   2978\u001b[0m \n\u001b[1;32m   2979\u001b[0m \u001b[38;5;124;03m  @tf.contrib.eager.defun\u001b[39;00m\n\u001b[1;32m   2980\u001b[0m \u001b[38;5;124;03m  def lossy_matmul(W, x, training=True):\u001b[39;00m\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;124;03m    outputs = tf.matmul(W, x)\u001b[39;00m\n\u001b[1;32m   2982\u001b[0m \u001b[38;5;124;03m    if training:\u001b[39;00m\n\u001b[1;32m   2983\u001b[0m \u001b[38;5;124;03m      outputs = tf.nn.dropout(outputs, keep_probability=0.2)\u001b[39;00m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;124;03m    return outputs\u001b[39;00m\n\u001b[1;32m   2985\u001b[0m \n\u001b[1;32m   2986\u001b[0m \u001b[38;5;124;03m  W = tf.random.normal((3, 5))\u001b[39;00m\n\u001b[1;32m   2987\u001b[0m \u001b[38;5;124;03m  x = tf.random.normal((5, 1))\u001b[39;00m\n\u001b[1;32m   2988\u001b[0m \n\u001b[1;32m   2989\u001b[0m \u001b[38;5;124;03m  # Executes a graph that applies dropout.\u001b[39;00m\n\u001b[1;32m   2990\u001b[0m \u001b[38;5;124;03m  lossy_outputs = lossy_matmul(W, x, training=True)\u001b[39;00m\n\u001b[1;32m   2991\u001b[0m \n\u001b[1;32m   2992\u001b[0m \u001b[38;5;124;03m  # Executes a graph that does not apply dropout.\u001b[39;00m\n\u001b[1;32m   2993\u001b[0m \u001b[38;5;124;03m  exact_outputs = lossy_matmul(W, x, training=False)\u001b[39;00m\n\u001b[1;32m   2994\u001b[0m \u001b[38;5;124;03m  ```\u001b[39;00m\n\u001b[1;32m   2995\u001b[0m \n\u001b[1;32m   2996\u001b[0m \u001b[38;5;124;03m  _TensorFlow Control Flow_\u001b[39;00m\n\u001b[1;32m   2997\u001b[0m \n\u001b[1;32m   2998\u001b[0m \u001b[38;5;124;03m  When `autograph` is `True`, data-dependent control flow is allowed as well.\u001b[39;00m\n\u001b[1;32m   2999\u001b[0m \u001b[38;5;124;03m  Control flow statements that depend on `Tensor` values are staged into\u001b[39;00m\n\u001b[1;32m   3000\u001b[0m \u001b[38;5;124;03m  corresponding TensorFlow ops. For example, the following code will work as\u001b[39;00m\n\u001b[1;32m   3001\u001b[0m \u001b[38;5;124;03m  expected:\u001b[39;00m\n\u001b[1;32m   3002\u001b[0m \n\u001b[1;32m   3003\u001b[0m \u001b[38;5;124;03m  ```python\u001b[39;00m\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;124;03m  @tf.contrib.eager.defun\u001b[39;00m\n\u001b[1;32m   3005\u001b[0m \u001b[38;5;124;03m  def dynamic_rnn_loop(cell, seq):\u001b[39;00m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;124;03m    state, output = cell.zero_state()\u001b[39;00m\n\u001b[1;32m   3007\u001b[0m \u001b[38;5;124;03m    for input in seq:\u001b[39;00m\n\u001b[1;32m   3008\u001b[0m \u001b[38;5;124;03m      state, output = cell(input, state)\u001b[39;00m\n\u001b[1;32m   3009\u001b[0m \u001b[38;5;124;03m    return output\u001b[39;00m\n\u001b[1;32m   3010\u001b[0m \u001b[38;5;124;03m  ```\u001b[39;00m\n\u001b[1;32m   3011\u001b[0m \n\u001b[1;32m   3012\u001b[0m \u001b[38;5;124;03m  For more information see `tf.autograph`.\u001b[39;00m\n\u001b[1;32m   3013\u001b[0m \n\u001b[1;32m   3014\u001b[0m \u001b[38;5;124;03m  _Variables_\u001b[39;00m\n\u001b[1;32m   3015\u001b[0m \n\u001b[1;32m   3016\u001b[0m \u001b[38;5;124;03m  TensorFlow operations related to variable creation and initialization are\u001b[39;00m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;124;03m  automatically lifted out of the graphs generated by `defun`. In practice, this\u001b[39;00m\n\u001b[1;32m   3018\u001b[0m \u001b[38;5;124;03m  implies that variable creation and initialization only happen the first time\u001b[39;00m\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;124;03m  `F` is called, and that variables are reused every time thereafter. Many\u001b[39;00m\n\u001b[1;32m   3020\u001b[0m \u001b[38;5;124;03m  TensorFlow APIs, like `tf.keras.layers.Layer` objects, create variables the\u001b[39;00m\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;124;03m  first time they are called and reuse them thereafter. Automatic variable\u001b[39;00m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;124;03m  lifting makes it possible to compile these APIs without extra effort, at the\u001b[39;00m\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;124;03m  cost of introducing a discrepancy between the semantics of executing Python\u001b[39;00m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;124;03m  functions and their corresponding compiled functions. For example:\u001b[39;00m\n\u001b[1;32m   3025\u001b[0m \n\u001b[1;32m   3026\u001b[0m \u001b[38;5;124;03m  ```python\u001b[39;00m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;124;03m  import tensorflow as tf\u001b[39;00m\n\u001b[1;32m   3028\u001b[0m \n\u001b[1;32m   3029\u001b[0m \u001b[38;5;124;03m  tf.compat.v1.enable_eager_execution()\u001b[39;00m\n\u001b[1;32m   3030\u001b[0m \n\u001b[1;32m   3031\u001b[0m \u001b[38;5;124;03m  def fn():\u001b[39;00m\n\u001b[1;32m   3032\u001b[0m \u001b[38;5;124;03m    x = tf.Variable(0.0)\u001b[39;00m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;124;03m    x.assign_add(1.0)\u001b[39;00m\n\u001b[1;32m   3034\u001b[0m \u001b[38;5;124;03m    return x.read_value()\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \n\u001b[1;32m   3036\u001b[0m \u001b[38;5;124;03m  # `fn` is a Python function, so x is created, initialized, and destroyed upon\u001b[39;00m\n\u001b[1;32m   3037\u001b[0m \u001b[38;5;124;03m  # every invocation\u001b[39;00m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;124;03m  assert fn().numpy() == fn().numpy() == 1.0\u001b[39;00m\n\u001b[1;32m   3039\u001b[0m \n\u001b[1;32m   3040\u001b[0m \u001b[38;5;124;03m  compiled = tf.contrib.eager.defun(fn)\u001b[39;00m\n\u001b[1;32m   3041\u001b[0m \n\u001b[1;32m   3042\u001b[0m \u001b[38;5;124;03m  # Compiling `fn` with `defun` hoists all variables outside of the generated\u001b[39;00m\n\u001b[1;32m   3043\u001b[0m \u001b[38;5;124;03m  # graph, so initialization happens exactly once.\u001b[39;00m\n\u001b[1;32m   3044\u001b[0m \u001b[38;5;124;03m  assert compiled().numpy() == 1.0\u001b[39;00m\n\u001b[1;32m   3045\u001b[0m \u001b[38;5;124;03m  assert compiled().numpy() == 2.0\u001b[39;00m\n\u001b[1;32m   3046\u001b[0m \u001b[38;5;124;03m  ```\u001b[39;00m\n\u001b[1;32m   3047\u001b[0m \n\u001b[1;32m   3048\u001b[0m \u001b[38;5;124;03m  Finally, because each input signature is bound to a unique graph, if your\u001b[39;00m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;124;03m  Python function constructs `tf.Variable` objects, then each graph constructed\u001b[39;00m\n\u001b[1;32m   3050\u001b[0m \u001b[38;5;124;03m  for that Python function will reference a unique set of variables. To\u001b[39;00m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;124;03m  circumvent this problem, we recommend against compiling Python functions that\u001b[39;00m\n\u001b[1;32m   3052\u001b[0m \u001b[38;5;124;03m  create `tf.Variable` objects. Instead, Python functions should either\u001b[39;00m\n\u001b[1;32m   3053\u001b[0m \u001b[38;5;124;03m  lexically close over `tf.Variable` objects or accept them as arguments,\u001b[39;00m\n\u001b[1;32m   3054\u001b[0m \u001b[38;5;124;03m  preferably encapsulated in an object-oriented container. If you must create\u001b[39;00m\n\u001b[1;32m   3055\u001b[0m \u001b[38;5;124;03m  variables inside your Python function and you want each graph generated for it\u001b[39;00m\n\u001b[1;32m   3056\u001b[0m \u001b[38;5;124;03m  to reference the same set of variables, add logic to your Python function that\u001b[39;00m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;124;03m  ensures that variables are only created the first time it is called and are\u001b[39;00m\n\u001b[1;32m   3058\u001b[0m \u001b[38;5;124;03m  reused for every subsequent invocation; note that this is precisely what\u001b[39;00m\n\u001b[1;32m   3059\u001b[0m \u001b[38;5;124;03m  `tf.keras.layers.Layer` objects do, so we recommend using them to represent\u001b[39;00m\n\u001b[1;32m   3060\u001b[0m \u001b[38;5;124;03m  variable-bearing computations whenever possible.\u001b[39;00m\n\u001b[1;32m   3061\u001b[0m \n\u001b[1;32m   3062\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \u001b[38;5;124;03m    func: function to be compiled. If `func` is None, returns a\u001b[39;00m\n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m      decorator that can be invoked with a single argument - `func`. The\u001b[39;00m\n\u001b[1;32m   3065\u001b[0m \u001b[38;5;124;03m      end result is equivalent to providing all the arguments up front.\u001b[39;00m\n\u001b[1;32m   3066\u001b[0m \u001b[38;5;124;03m      In other words, defun(input_signature=...)(func) is equivalent to\u001b[39;00m\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;124;03m      defun(func, input_signature=...). The former allows\u001b[39;00m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m      the following use case:\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m        @tf.contrib.eager.defun(input_signature=...)\u001b[39;00m\n\u001b[1;32m   3070\u001b[0m \u001b[38;5;124;03m        def foo(...):\u001b[39;00m\n\u001b[1;32m   3071\u001b[0m \u001b[38;5;124;03m          ...\u001b[39;00m\n\u001b[1;32m   3072\u001b[0m \n\u001b[1;32m   3073\u001b[0m \u001b[38;5;124;03m    input_signature: A possibly nested sequence of\u001b[39;00m\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;124;03m      `tf.contrib.eager.TensorSpec` objects specifying the shapes and dtypes of\u001b[39;00m\n\u001b[1;32m   3075\u001b[0m \u001b[38;5;124;03m      the Tensors that will be supplied to this function. If `None`, a separate\u001b[39;00m\n\u001b[1;32m   3076\u001b[0m \u001b[38;5;124;03m      function is instantiated for each inferred input signature.  If a\u001b[39;00m\n\u001b[1;32m   3077\u001b[0m \u001b[38;5;124;03m      signature is specified, every input to `func` must be a `Tensor`, and\u001b[39;00m\n\u001b[1;32m   3078\u001b[0m \u001b[38;5;124;03m      `func` cannot accept `**kwargs`.\u001b[39;00m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;124;03m    autograph: Whether `func` should be compiled before\u001b[39;00m\n\u001b[1;32m   3080\u001b[0m \u001b[38;5;124;03m      constructing the graph. See https://www.tensorflow.org/guide/autograph\u001b[39;00m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;124;03m      for more information.\u001b[39;00m\n\u001b[1;32m   3082\u001b[0m \u001b[38;5;124;03m    experimental_autograph_options: Experimental knobs (in the form of a tuple\u001b[39;00m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;124;03m      of tensorflow.autograph.Feature values) to control behavior when\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;124;03m      autograph=True.\u001b[39;00m\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;124;03m    reduce_retracing: When True, `tf.function` uses\u001b[39;00m\n\u001b[1;32m   3086\u001b[0m \u001b[38;5;124;03m      `tf.types.experimental.TraceType` to trace supertypes of arguments to\u001b[39;00m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;124;03m      reduce the number of traces.\u001b[39;00m\n\u001b[1;32m   3088\u001b[0m \n\u001b[1;32m   3089\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m   3090\u001b[0m \u001b[38;5;124;03m     If `func` is not None, returns a callable that will execute the compiled\u001b[39;00m\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;124;03m     function (and return zero or more `tf.Tensor` objects).\u001b[39;00m\n\u001b[1;32m   3092\u001b[0m \u001b[38;5;124;03m     If `func` is None, returns a decorator that, when invoked with a single\u001b[39;00m\n\u001b[1;32m   3093\u001b[0m \u001b[38;5;124;03m     `func` argument, returns a callable equivalent to the case above.\u001b[39;00m\n\u001b[1;32m   3094\u001b[0m \n\u001b[1;32m   3095\u001b[0m \u001b[38;5;124;03m  Raises:\u001b[39;00m\n\u001b[1;32m   3096\u001b[0m \u001b[38;5;124;03m    TypeError: If `input_signature` is neither `None` nor a sequence of\u001b[39;00m\n\u001b[1;32m   3097\u001b[0m \u001b[38;5;124;03m      `tf.contrib.eager.TensorSpec` objects.\u001b[39;00m\n\u001b[1;32m   3098\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m   3099\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m defun_with_attributes(\n\u001b[1;32m   3100\u001b[0m       func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   3101\u001b[0m       input_signature\u001b[38;5;241m=\u001b[39minput_signature,\n\u001b[1;32m   3102\u001b[0m       autograph\u001b[38;5;241m=\u001b[39mautograph,\n\u001b[1;32m   3103\u001b[0m       experimental_autograph_options\u001b[38;5;241m=\u001b[39mexperimental_autograph_options,\n\u001b[1;32m   3104\u001b[0m       reduce_retracing\u001b[38;5;241m=\u001b[39mreduce_retracing)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     graph_input_shape \u001b[38;5;241m=\u001b[39m tensor_shape\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[1;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph\u001b[38;5;241m.\u001b[39minputs[i]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m graph_input_shape\u001b[38;5;241m.\u001b[39mis_compatible_with(tensor_input\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m   1847\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1848\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not compatible with the shape this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1849\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction was traced with. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1850\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph\u001b[38;5;241m.\u001b[39minputs[i]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1851\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_input\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you called get_concrete_function, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1852\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou may need to pass a tf.TensorSpec(..., shape=...) with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1853\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mless specific shape, having None on axes which can vary.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1855\u001b[0m args \u001b[38;5;241m=\u001b[39m tensor_inputs \u001b[38;5;241m+\u001b[39m captured_inputs\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m--> 499\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########## Training Start\n",
    "DeepLearning.fit_generator(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        #steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        \n",
    "        epochs=15,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=VALID_GENERATOR)\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42a25b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습하지 않았으므로, 강사가 학습한 모델 사용\n",
    "DeepLearning.load_weights(model_directory+'PretrainedVGG.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ba2fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DeepLearning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fccb6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18680\\324675668.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  TEST_Prediction = DeepLearning.predict_generator(TEST_GENERATOR, verbose=1)\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:1663: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:1671: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 9s 4s/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "TEST_Prediction = DeepLearning.predict_generator(TEST_GENERATOR, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8ff2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame으로 변환\n",
    "Result = pd.DataFrame(TEST_Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1105daa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'ROC Curves'}, xlabel='False Positive Rate', ylabel='True Positive Rate'>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "skplt.metrics.plot_roc(TEST_GENERATOR.classes.tolist(), Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5e81e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음과 같이 Back-bone model만 수정할 수 있다.\n",
    "'''\n",
    "\n",
    "Model = tf.keras.applications.VGG16(include_top=False,\n",
    "    weights='imagenet', input_tensor=None, input_shape=(img_width,img_height,3), pooling=None)\n",
    "\n",
    "Model = tf.keras.applications.ResNet101V2(include_top=False,\n",
    "    weights='imagenet', input_tensor=None, input_shape=(img_width,img_height,3), pooling=None)\n",
    "\n",
    "Model = tf.keras.applications.EfficientNetB4(include_top=False,\n",
    "    weights='imagenet', input_tensor=None, input_shape=(img_width,img_height,3), pooling=None)\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598abf6",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications?hl=ko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188b4a4",
   "metadata": {},
   "source": [
    "# GradCam visualization 시각화 Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1ea8c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "def grad_cam(model, img, layer_name=\"block5_conv3\", label_name=None, category_id=None):\n",
    "    img_tensor = np.expand_dims(img, axis=0)\n",
    "    conv_layer = model.get_layer(layer_name)\n",
    "    heatmap_model = tf.keras.Model(inputs=[model.inputs], outputs=[conv_layer.output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as gtape:\n",
    "        conv_output, predictions = heatmap_model(img_tensor)\n",
    "        if category_id == None:\n",
    "            category_id = np.argmax(predictions[0])\n",
    "        if label_name:\n",
    "            print(label_name[category_id])\n",
    "        output = predictions[:, category_id]\n",
    "        grads = gtape.gradient(output, conv_output)\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    max_heat = np.max(heatmap)\n",
    "    if max_heat == 0:\n",
    "        max_heat = 1e-10\n",
    "    heatmap /= max_heat\n",
    "    return np.squeeze(heatmap), predictions\n",
    "\n",
    "def grad_camAll(model, img, layer_name=\"conv4_block6_out\", blockSize=7, label_name=None, category_id=None):\n",
    "    img_tensor = np.expand_dims(img, axis=0)\n",
    "    conv_layer = model.get_layer(layer_name)\n",
    "    heatmap_model = Model([model.inputs], [conv_layer.output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as gtape:\n",
    "        conv_output, predictions = heatmap_model(img_tensor)\n",
    "        if category_id == None:\n",
    "            category_id = np.argmax(predictions[0])\n",
    "        if label_name:\n",
    "            print(label_name[category_id])\n",
    "        output = predictions[:, category_id]\n",
    "        grads = gtape.gradient(output, conv_output)\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    res = sp.ndimage.zoom(conv_output[0], (224/blockSize, 224/blockSize, 1), order=2)   \n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, res), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    max_heat = np.max(heatmap)\n",
    "    if max_heat == 0:\n",
    "        max_heat = 1e-10\n",
    "    heatmap /= max_heat\n",
    "    return np.squeeze(heatmap)\n",
    "\n",
    "def show_imgwithheat(img_path, heatmap, alpha=0.4, return_array=False):\n",
    "    img = cv2.imread(img_path)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = (heatmap*255).astype(\"uint8\")\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = heatmap * alpha + img\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(\"uint8\")\n",
    "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    imgwithheat = PIL.Image.fromarray(superimposed_img)  \n",
    "    display(imgwithheat)\n",
    "\n",
    "    if return_array:\n",
    "        return superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c651323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# CAM Generator\n",
    "CAM_GENERATOR = DATAGEN_TEST.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = 1,\n",
    "    shuffle = False,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0924d430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DeepLearning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "facbdbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for Iterator in range(0, 20):\n",
    "    Image, Label = CAM_GENERATOR.next()\n",
    "    Image = Image[0]\n",
    "    FileName = CAM_GENERATOR.filenames[Iterator]\n",
    "    # Final Layer\n",
    "    HEATMAP1, pred1 = grad_cam(model = DeepLearning, img = Image, layer_name = 'block5_conv3', category_id=0)\n",
    "    \n",
    "    heatmap1 = cv2.resize(HEATMAP1, (Image.shape[1], Image.shape[0]))\n",
    "    heatmap1 = (heatmap1*255).astype(\"uint8\")\n",
    "    heatmap1 = cv2.applyColorMap(heatmap1, cv2.COLORMAP_JET)\n",
    "\n",
    "    fig, ax = plt.subplots( nrows=3, ncols=1 )  # create figure & 1 axis\n",
    "    fig.set_size_inches(9.0, 3.0)\n",
    "    ax = plt.subplot(1,3,1)\n",
    "    ax.imshow(Image)\n",
    "    ax = plt.subplot(1,3,2)\n",
    "    ax.imshow(Image)\n",
    "    ax.imshow(255-heatmap1, cmap=plt.cm.jet, alpha=0.3, interpolation='nearest' )\n",
    "    ax = plt.subplot(1,3,3)\n",
    "    ax.imshow(Image)\n",
    "    ax.imshow(heatmap1, cmap=plt.cm.jet, alpha=0.3, interpolation='nearest' )\n",
    "\n",
    "    plt.subplots_adjust(left = 0.06, wspace = 0.25, hspace = 0.1, bottom = 0.025, top = 0.975)\n",
    "    pred=round(pred1.numpy()[0][0],3)\n",
    "    HeatImage = \"HEATMAP/0420_\"+CAM_GENERATOR.filenames[Iterator].split('\\\\')[1] + \"^\" + str(round(pred, 4)) + \".jpg\"\n",
    "    plt.savefig(HeatImage.strip(), bbox_inches = 'tight')\n",
    "    plt.close()\n",
    "    plt.cla()\n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
