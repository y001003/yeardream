{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, utils\n",
    "\n",
    "(train_data, train_label), (test_data, test_label) = datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data.reshape(60000, 784) / 255.0\n",
    "test_data = test_data.reshape(10000, 784) / 255.0\n",
    "\n",
    "train_label = utils.to_categorical(train_label) # 0~9 -> one-hot vector\n",
    "test_label = utils.to_categorical(test_label) # 0~9 -> one-hot vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32) # 살려줄 node의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "L1 = tf.nn.dropout(L1, keep_prob) # Dropout을 적용할 layer & 살릴 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob) # Dropout을 적용할 layer & 살릴 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Set the criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.losses.softmax_cross_entropy(Y, model) \n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "total_batch = int(len(train_data) / batch_size)\n",
    "print(total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 || Avg. Training cost = 0.407\n",
      "Epoch: 2 || Avg. Training cost = 0.155\n",
      "Epoch: 3 || Avg. Training cost = 0.104\n",
      "Epoch: 4 || Avg. Training cost = 0.082\n",
      "Epoch: 5 || Avg. Training cost = 0.063\n",
      "Epoch: 6 || Avg. Training cost = 0.054\n",
      "Epoch: 7 || Avg. Training cost = 0.045\n",
      "Epoch: 8 || Avg. Training cost = 0.040\n",
      "Epoch: 9 || Avg. Training cost = 0.034\n",
      "Epoch: 10 || Avg. Training cost = 0.031\n",
      "Epoch: 11 || Avg. Training cost = 0.030\n",
      "Epoch: 12 || Avg. Training cost = 0.027\n",
      "Epoch: 13 || Avg. Training cost = 0.025\n",
      "Epoch: 14 || Avg. Training cost = 0.021\n",
      "Epoch: 15 || Avg. Training cost = 0.023\n",
      "Learning process is completed!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    \n",
    "    \n",
    "    total_cost = 0\n",
    "    batch_idx = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        batch_x = train_data[ batch_idx : batch_idx + batch_size ]\n",
    "        batch_y = train_label[ batch_idx : batch_idx + batch_size ]\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={X: batch_x, \n",
    "                                       Y: batch_y, \n",
    "                                       keep_prob: 0.8}) # node 중 80%만 유지하고 20%를 train 시마다 off\n",
    "        \n",
    "        batch_cost = sess.run(cost, feed_dict={X: batch_x, \n",
    "                                               Y: batch_y, \n",
    "                                               keep_prob: 0.8})\n",
    "        total_cost = total_cost + batch_cost\n",
    "        \n",
    "        batch_idx += batch_size\n",
    "    \n",
    "    \n",
    "    training_cost = total_cost / total_batch\n",
    "    \n",
    "    \n",
    "    print('Epoch: {}'.format(epoch + 1), \n",
    "          '|| Avg. Training cost = {:.3f}'.format(training_cost))\n",
    "\n",
    "print('Learning process is completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9806\n"
     ]
    }
   ],
   "source": [
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: test_data,\n",
    "                                   Y: test_label,\n",
    "                                   keep_prob: 1})) # 정확도를 측정하는 Test 단계에서는 전체 Node를 살려줘야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### + Appendix. Save the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# 모델의 예측값을 labels에 저장\n",
    "labels = sess.run(tf.argmax(model, 1),\n",
    "                  feed_dict={X: test_data,\n",
    "                             Y: test_label,\n",
    "                             keep_prob: 1}) \n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "# for i in range(10):\n",
    "#     subplot = fig.add_subplot(2, 5, i + 1)\n",
    "#     subplot.set_xticks([])\n",
    "#     subplot.set_yticks([])\n",
    "#     subplot.set_title('%d' % labels[i])\n",
    "#     subplot.imshow(test_data[i].reshape((28, 28)),\n",
    "#                    cmap=plt.cm.gray_r)\n",
    "\n",
    "# plt.show() # 상단의 번호가 예측된 숫자, 아래의 이미지가 실제 데이터(이미지 내 숫자)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
