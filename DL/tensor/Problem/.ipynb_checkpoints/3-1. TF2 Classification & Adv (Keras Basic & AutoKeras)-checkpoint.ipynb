{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow.keras 공식 문서 (Official API Docs) @ https://www.tensorflow.org/api_docs/python/tf/keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.? import datasets, models, layers, utils, losses # tf.keras 에 필요한 함수들이 모여있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "#### 1. Prepare train & test data (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_label), (test_data, test_label) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape) # # of training data == 60000, each data = 28px * 28px\n",
    "print(test_data.shape) # # of test data == 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_data[0], cmap='gray') # 60000장의 train data 중 첫번째 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 이미지(28px * 28px)는 0~255 사이의 숫자로 이루어져 있습니다.\n",
    "\n",
    "print(train_data.min())\n",
    "print(train_data.max()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 이미지를 [28행 x 28열]에서 [1행 x 784열]로 펼쳐줍니다. \n",
    "# 각 이미지 내의 pixel 값을 [0~255]에서 [0~1]로 바꿔줍니다.\n",
    "\n",
    "train_data = train_data.reshape(60000, 784) / 255.0\n",
    "test_data = test_data.reshape(10000, 784) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 이미지에 대한 label은 integer value로 이루어져 있습니다.\n",
    "\n",
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 label을 integer value에서 one-hot vector로 변경해줍니다. (Tensorflow 2.x 활용)\n",
    "\n",
    "train_label = utils.to_categorical(train_label) # 0~9 -> one-hot vector\n",
    "test_label = utils.to_categorical(test_label) # 0~9 -> one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존의 integer label들이 아래와 같은 one-hot vector들로 변경된 것을 확인할 수 있습니다.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(train_label).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "#### 2. Build the model & Set the criterion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.?() # Build up the \"Sequence\" of layers (Linear stack of layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.?(input_dim=28*28, units=512, activation='?', kernel_initializer='?_uniform')) # Dense-layer (relu & he)\n",
    "model.add(layers.?(0.2)) # Dropout-layer\n",
    "model.add(layers.?(units=10, activation='?')) # (Output) Dense-layer with softmax function, 0~9 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Compile\" the model description (Configures the model for training)\n",
    "model.?(optimizer='adam', \n",
    "              loss=losses.categorical_crossentropy, # See other available losses @ https://keras.io/losses/\n",
    "              metrics=['accuracy']) # TF 2.X 에서 Precision / Recall / F1-Score 적용하기 @ https://j.mp/3cf3lbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Regression\n",
    "# model.add(layers.Dense(units=1, activation=None))\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=losses.mean_squared_error,\n",
    "#               metrics=['mean_squared_error']) \n",
    "\n",
    "# # Multi-class classification\n",
    "# model.add(layers.Dense(units=10, activation='softmax'))\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=losses.categorical_crossentropy,        # <- Label이 One-hot 형태일 경우\n",
    "#               loss=losses.sparse_categorical_crossentropy, # <- Label이 One-hot 형태가 아닐 경우\n",
    "#               metrics=['accuracy']) \n",
    "\n",
    "# # Binary Classification 1 (Softmax를 적용하는 경우, recommended)\n",
    "# model.add(layers.Dense(units=2, activation='softmax'))\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=losses.categorical_crossentropy,\n",
    "#               metrics=['accuracy']) \n",
    "\n",
    "# # Binary Classification 2 (Sigmoid를 적용하는 경우)\n",
    "# # 선형결합 결과에 대해 sigmoid function의 output을 계산해주면, binary_crossentropy가 이를 음성 & 양성 확률로 변환하여 처리해줍니다.\n",
    "# model.add(layers.Dense(units=1, activation='sigmoid')) \n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=losses.binary_crossentropy, \n",
    "#               metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "#### 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "\n",
    "model.?(train_data, train_label, batch_size=100, epochs=10) # default batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "#### 4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "\n",
    "result = model.?(test_data, test_label, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loss (cross-entropy) :', result[0])\n",
    "print('test accuracy :', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### (Appendix 1) tf.keras.layers.Flatten() 활용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_label), (test_data, test_label) = datasets.mnist.load_data()\n",
    "\n",
    "# 아래 코드에서 reshape 적용을 생략하고, 대신 Flatten 레이어를 활용해 펼쳐낼 수 있습니다.\n",
    "# train_data = train_data.reshape(60000, 784) / 255.0\n",
    "# test_data = test_data.reshape(10000, 784) / 255.0\n",
    "\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "train_label = utils.to_categorical(train_label)\n",
    "test_label = utils.to_categorical(test_label)\n",
    "\n",
    "\n",
    "model = models.Sequential() \n",
    "\n",
    "model.add(layers.Flatten()) # takes our 28x28 and makes it 1x784\n",
    "\n",
    "# model.add(layers.Dense(input_dim=28*28, units=512, activation='relu', kernel_initializer='he_uniform')) \n",
    "model.add(layers.Dense(units=512, activation=tf.nn.relu, kernel_initializer='he_uniform')) # tf.nn 활용이 가능합니다.\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(units=10, activation=tf.nn.softmax)) # tf.nn 활용이 가능합니다.\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss=losses.categorical_crossentropy, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_label, batch_size=100, epochs=10) \n",
    "\n",
    "result = model.evaluate(test_data, test_label, batch_size=100)\n",
    "print('loss (cross-entropy) :', result[0])\n",
    "print('test accuracy :', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### (Appendix 2) AutoKeras 활용법 (https://autokeras.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\* <span style=\"color:blue;\">AutoKeras보다 더 유용한 도구인 Keras-Tuner를 곧 학습할 예정입니다.</span>**\n",
    "\n",
    "\\* PyTorch 및 AutoKeras 설치 & AutoKeras fitting 과정에 시간이 무척 많이 소요됩니다.\n",
    "<br>\\* 개발환경이 영향을 받을 수 있으니 아래 코드는 **<span style=\"color:red;\">Google Colab 에서 실행</span>**하시는 것을 적극 권장합니다. (혹은 Conda 가상환경 활용)\n",
    "<br>\\* 금일 실습을 마치고 추후 복습하실 때 살펴보세요.\n",
    "<br><br>\n",
    "\n",
    "1) 먼저 OS에 맞는 pytorch를 설치해주어야 합니다. (available pip whl files @ https://goo.gl/uYVaPa)\n",
    "\n",
    ">conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
    "\n",
    "2) 그 다음 아래 명령어로 AutoKeras를 설치해줍니다.\n",
    "\n",
    "> pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets, models, layers, utils\n",
    "(train_data, train_label), (test_data, test_label) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "model = ak.ImageClassifier() # It searches CNN architectures for the best configuration for the image dataset.\n",
    "model.fit(train_data, train_label, time_limit=3600) # time_limit: The time limit for the search in seconds.\n",
    "\n",
    "accuracy = model.evaluate(test_data, test_label)\n",
    "result = model.predict(test_data)\n",
    "\n",
    "print(accuracy)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Appendix \n",
    "- Automated Machine Learning with Auto-Keras @ http://j.mp/2xeG2c2\n",
    "- Keras vs PyTorch @ https://goo.gl/ar5VPB"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
