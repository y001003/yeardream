{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, utils\n",
    "\n",
    "(train_data, train_label), (test_data, test_label) = datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data.reshape(60000, 784) / 255.0\n",
    "test_data = test_data.reshape(10000, 784) / 255.0\n",
    "\n",
    "train_label = utils.to_categorical(train_label) # 0~9 -> one-hot vector\n",
    "test_label = utils.to_categorical(test_label) # 0~9 -> one-hot vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout을 적용하며 layer마다 살려줄 node의 비율을 지정합니다.\n",
    "# 이 때에도 placeholder를 사용해야 합니다.\n",
    "\n",
    "keep_prob = tf.?(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "L1 = tf.nn.?(L1, keep_prob) # (Dropout을 적용할 layer, 살릴 비율)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "L2 = tf.nn.?(L2, keep_prob) # Dropout을 적용할 layer & 살릴 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Set the criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.losses.softmax_cross_entropy(Y, model) \n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "total_batch = int(len(train_data) / batch_size)\n",
    "print(total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(15):\n",
    "    \n",
    "    \n",
    "    total_cost = 0\n",
    "    batch_idx = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        batch_x = train_data[ batch_idx : batch_idx + batch_size ]\n",
    "        batch_y = train_label[ batch_idx : batch_idx + batch_size ]\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={X: batch_x, \n",
    "                                       Y: batch_y, \n",
    "                                       ?: 0.8}) # 살릴 비율 지정, node 중 80%만 유지하고 20%를 train 시마다 off\n",
    "        \n",
    "        batch_cost = sess.run(cost, feed_dict={X: batch_x, \n",
    "                                               Y: batch_y, \n",
    "                                               ?: 0.8}) # 살릴 비율 지정, node 중 80%만 유지하고 20%를 train 시마다 off\n",
    "        total_cost = total_cost + batch_cost\n",
    "        \n",
    "        batch_idx += batch_size\n",
    "    \n",
    "    \n",
    "    training_cost = total_cost / total_batch\n",
    "    \n",
    "    \n",
    "    print('Epoch: {}'.format(epoch + 1), \n",
    "          '|| Avg. Training cost = {:.3f}'.format(training_cost))\n",
    "\n",
    "print('Learning process is completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: test_data,\n",
    "                                   Y: test_label,\n",
    "                                   ?: 1})) # 살릴 비율 지정, 정확도를 측정하는 Test 단계에서는 전체 Node를 살려줘야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### + Appendix. Save the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 예측값을 labels에 저장\n",
    "labels = sess.run(tf.argmax(model, 1),\n",
    "                  feed_dict={X: test_data,\n",
    "                             Y: test_label,\n",
    "                             keep_prob: 1}) \n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "# for i in range(10):\n",
    "#     subplot = fig.add_subplot(2, 5, i + 1)\n",
    "#     subplot.set_xticks([])\n",
    "#     subplot.set_yticks([])\n",
    "#     subplot.set_title('%d' % labels[i])\n",
    "#     subplot.imshow(test_data[i].reshape((28, 28)),\n",
    "#                    cmap=plt.cm.gray_r)\n",
    "\n",
    "# plt.show() # 상단의 번호가 예측된 숫자, 아래의 이미지가 실제 데이터(이미지 내 숫자)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
